<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Ayden Cole</title>
        <description>Bracia is a simple personal blog theme for Jekyll.</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Mon, 08 Sep 2025 17:27:57 -0700</pubDate>
        <lastBuildDate>Mon, 08 Sep 2025 17:27:57 -0700</lastBuildDate>
        <generator>Jekyll v4.4.1</generator>
        
            <item>
                <title>Three Types of Risk with Traditional AI</title>
                <description>&lt;h3 id=&quot;some-lurking-problems&quot;&gt;Some lurking problems…&lt;/h3&gt;

&lt;p&gt;When people bring up their fears about AI (Artificial Intelligence), it’s common to hear concerns like mass unemployment, a total blurring of real and fake news, or nuclear Armageddon. Those might all be valid fears, but they mostly revolve around the development of AGI (Artificial General Intelligence), which is only hypothetical at this point in time. I have a few other concerns that are more immediate, since they have to do with the way modern AI is already being used. They are all security focused, of course. Here are the issues I see – Generative AI, the way most of us use it now, makes us more vulnerable to threats like data breaches, system failure, and ironically enough, obsolescence.&lt;/p&gt;

&lt;h5 id=&quot;data&quot;&gt;Data&lt;/h5&gt;

&lt;p&gt;We all know AI is trained on nearly inconceivable swathes of data and that AI companies like Open AI are hungry for even more. So when we discuss user inputs, it’s natural to think of that in the context of how AI companies are using your input to train their AI. I have sometimes heard complaints from people who don’t like the way their data is being used to advance AI in ways they might think are unethical. But what gets less attention is what kinds of sensitive data users might be entering, and how good, old-fashioned social engineering could lead users to put the wrong information into the wrong hands.&lt;/p&gt;

&lt;p&gt;AI can prompt users to enter more data than they might ever trust to the Google search engine. When people use a web search engine, they are rewarded for inputting precise, jargon-free queries. However, AI responds better to more sophisticated kinds of queries. A helpful acronym for building a strong AI prompt I learned from my Google Cybersecurity Certificate is TCREI (Task, Context, References, Evaluate, Iterate). Even if people don’t know this specific acronym ahead of time, they will learn these principles through trial-and-error interacting with AI. Consider how data fits into TCREI – AI prompts require a lot more data than a web search. And not just in terms of bytes! Context and references contain the personal details that we usually leave out in a web search.&lt;/p&gt;

&lt;p&gt;As an example, imagine you’re looking for a movie to watch. If you’re Googling, you might try a search like “best sci fi movies on Netflix.” If you’re not happy with the search results, you might try a couple iterations like adding “right now” or swapping “movies” for “shows,” but that might be the extent. Now imaging you’re asking AI like Google Gemini for movies to watch. A good prompt might look something like this.
***&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;“Hi Gemini! I need your help finding something sci fi to watch tonight (Task). I have a couple hours to kill so anything goes, but it will need to be on Netflix or HBO Max, since those are the only streaming services I have (Context). Just to give you an idea, last night I watched the Clover field Paradox and really enjoyed that (Reference). Can you give me a couple suggestions?” *** 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is an effective prompt (see the response in the notes at the end if you like), but notice how personal data it contains. Interacting with a chat bot is designed to feel like talking with a person, so it can seem innocuous to provide this level of detail. Here is the scenario that concerns me though. If a malicious actor were to gain access to the AI’s programming, they could cause the AI to request increasingly sensitive data from the user. AI responses often end with a request for additional information. A bad actor could program AI to ask for revealing information like banking info, HIPPA protected data, etc. They wouldn’t even have to gain access to a proprietary model like Gemini; they could simply using social engineering like phishing and spoof Gemini, so unsuspecting users think their information is going to Google but it’s really going directly into the wrong hands.&lt;/p&gt;

&lt;p&gt;To wrap up my concerns about data, it has less to do with how AI companies use or store that data, and more to do with two potential rungs of social engineering. The first rung is hacking or spoofing, so users think they’re communicating with a proprietary model, but their information is really being intercepted or going straight to bad people. The second, more unique rung, is commanding AI to lure users into a false sense of security and nudging them to give away compromising information.&lt;/p&gt;

&lt;h5 id=&quot;cloud-dependence&quot;&gt;Cloud Dependence&lt;/h5&gt;

&lt;p&gt;All the popular AI models people are using – be that Gemini, ChatGPT, or one of many others – are being accessed in the cloud. As these AI models are integrated into more and more settings, we will likely become more dependent on cloud security. In most enterprise settings, we utilize a hybrid approach and migrate some things into the cloud while keeping our most critical data safe at home on our local networks. The cloud may be sophisticated, but it still presents a large attack surface after all. But our tendency to access AI capabilities via a single vector could lead to a tipping point where segmentation is neglected and critical processes are thoughtlessly migrated to the cloud.&lt;/p&gt;

&lt;p&gt;Some of these concerns stem from my work experience in the medical field. Medicine is ripe for the introduction of AI. For example, one of the current pain points in the field is the time it takes to get scans read. For a variety of reasons, the supply of radiologists is increasing while the number of patients is growing. AI could solve this problem beautifully by providing fast and inexpensive scan results. Here is the nuance though. It’s already too expensive and time-consuming to become a radiologist, which is part of why we don’t have enough of them. If medical institutions rush to use AI-radiologists and stop hiring real people, we will throttle the supply of people who can read scans. This may be well and good if the AI works, but consider where we’re keeping the AI – in centralized cloud data centers with massive attack surfaces that we depend on network connectivity to access.&lt;/p&gt;

&lt;p&gt;It’s never a good idea to put all your eggs in one basket. The current medical system, expensive and inefficient as it may be, at least has the benefit of redundancy and decentralization. There are radiologists all around the country who can read our scans. If someone quits, someone else will take their place. The same thing goes in many other industries. I’m not saying we can’t implement a high degree of resiliency into the digital world. Cloud providers can build more data centers and we can incorporate more routes to connect to the internet, whether that is more cities installing fiber optic lines or Star Link putting up more satellites. But what I am saying is that these fail-safes will need to be planned from the start, and we have to bear in mind that every new data center or internet connection expands an object’s attack surface.&lt;/p&gt;

&lt;h5 id=&quot;obsolescence&quot;&gt;Obsolescence&lt;/h5&gt;

&lt;p&gt;Security through obscurity is the concept of preventing attacks by keeping your system designs a secret. Although at first glance it seems like a smart idea, it is widely concerned to be bad Cybersecurity practice. It works as a band-aid since it takes more time for hackers to map out your system before they can attack, but it doesn’t allow you to evolve quickly. A better solution is open-source, where more eyes and more contributors mean flaws get spotted and patched in real time. In the AI space, the conversation is centered on performance, not security, so all secrets are trade secrets. AI models are proprietary, not open-source. This approach is key to getting a competitive edge in the marketplace, but it’s not the best practice for making systems secure. In fact, from a security perspective, security through obscurity in AI could ultimately lead to obsolescence – hackers will eventually map out the attack surface in detail, and then companies may not be able to keep up with their ability to find new vectors.&lt;/p&gt;

&lt;h3 id=&quot;looking-forward&quot;&gt;Looking forward&lt;/h3&gt;

&lt;p&gt;If we continue to expand our AI use without seriously grappling with its security flaws, we risk the confidentiality of our data and the integrity of our systems, and we reduce the availability of its full potential to a select few powerful people. Since AI is being adopted so rapidly, I think it’s reasonable to harp on these failures. However, it’s clear that certain features of AI could be radically effective at solving pain points in industries ranging from radiology to entertainment. AI is here to stay. With that in mind, we need to start thinking in terms of solutions, not just worst case scenarios. And there are solutions! They have not gotten a lot of limelight yet, but I believe we have alternatives that will strengthen all three pillars of the aforementioned CIA triad. In my next post, I will discuss one alternative that I consider to be the most secure option on the market – offline, open-source AI.&lt;/p&gt;
</description>
                <pubDate>Tue, 02 Sep 2025 10:15:08 -0700</pubDate>
                <link>http://localhost:4000/third-post</link>
                <guid isPermaLink="true">http://localhost:4000/third-post</guid>
                
                <category>study</category>
                
                <category>personal</category>
                
                
            </item>
        
            <item>
                <title>Getting Started on Network Plus</title>
                <description>&lt;p&gt;After completing my Google Cybersecurity Certificate, I took a moment for some introspection and realized that the toughest parts of the course for me had been learning the OSI model. Even though I had managed to regurgitate all the information the course taught about OSI, I didn’t feel like I truly understood it. I certainly didn’t undernstand it in a way that I could explain to someone else. With that in mind, I went ahead and bought a voucher for the CompTIA Network+ and started gameplanning.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The CompTIA Network+ gets into the nitty-gritty of the Open Systems Interconnection (OSI) model and you have to memorize and understand details all the way from Level 1, like the actually wires plugged into your desktop, all the way up to Level 7, the applications you visually interact with on the web. Networking is a bit of a wooley mammoth. It is a gargantuan subject.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Networking is a bit of a wooley mammoth. It is a gargantuan subject.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After consulting with Grok, I started by watching a course overview video from Professor Messer. Then I made a print out and read the CompTIA Network+ Objectives. The objectives not only include the subjects you need to understand, they include a long list of acronyms you need to know. So I took a couple hours and made notecards for all the acronyms. Yes, it took a couple hours - an hour and forty-five minutes to be exact. There were a lot of acronyms!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Here is my plan. I will go through the flashcards every day, every opportunity I get. And I will watch through the Professor Messer Network+ 10-009 videos, taking notes and adding flashcards along the way. When I am done doing that, I will buy Jason Dion’s practice exams and take those, studying and refining my approach each time.&lt;/p&gt;

&lt;p&gt;There are 12 hours of content in the Professor Messer videos. I’m still working full time, so I am allowing a full week to watch all this. I might devote a second week to rewatch everything and continue working on my flashcards and reviewing my notes. We will see how things go. Otherwise, the next step is to devote a week to taking the Jason Dion practice exams, and working on the weaknesses those reveal. And finally, I will take the course the third/fourth week.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/images/06.jpg&quot; alt=&quot;Dark Brain&quot; style=&quot;width: 100%; height: auto;&quot; /&gt;
&lt;em&gt;Image generated by AI&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This is a skeleton of a plan. But I’m keeping it barebones for a reason. My intuition says passing this exam comes down to drilling down into IT fundamentals and using rote-memorization to learn the concepts. I don’t expect I will need any elaborate study plans or fancy study methods. I might turn out to be wrong, in which case I will post about it here and explain what extracurricular tools I ended up adding.&lt;/p&gt;

&lt;p&gt;Either way, this course is a means to an end. I want to understand network systems so I can understand how to secure them better, not because networks are my passion. So I am excited to have a challenge, but I am even more excited have this done and move on to my Security+. Let’s hope it doesn’t take too long!&lt;/p&gt;
</description>
                <pubDate>Sun, 17 Aug 2025 10:51:42 -0700</pubDate>
                <link>http://localhost:4000/second_post</link>
                <guid isPermaLink="true">http://localhost:4000/second_post</guid>
                
                <category>study</category>
                
                <category>networking</category>
                
                
            </item>
        
            <item>
                <title>Hello World!</title>
                <description>&lt;p&gt;My name is Ayden, and I am a 25 year old Pacific NorthWest native. I love to run and hike the local trails like Timberline Trail which loops all the way around Mt. Hood. I also enjoy scifi shows and I’ve recently been getting into cooking. My professional background is in healthcare and mental health. I majored with a Bachelors of Science in Psychology at Oklahoma Christian University, and I’ve worked at places like Cascadia Behavioral Healthcare, Amen Clinic, and Compass Oncology.&lt;/p&gt;

&lt;p&gt;I’ve recently started a career switch from healthcare to cybersecurity. I felt like I had plateaued and work wasn’t making me grow. I remembered back in high school when I took a free online course called “Learn Python the Hard Way” by Zed Shaw. The constant challenges and new lessons kept me captivated for months. So I figured I would revisit the world of the internet of things, and take a free course from Cisco called “Introduction to Cybersecurity.”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/08.jpg&quot; alt=&quot;Dark Brain&quot; style=&quot;width: 100%; height: auto;&quot; /&gt;
&lt;em&gt;Image generated by AI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I got a concussion on one of my adventures on Mt. Hood and the doctor said to take a week off work. During that time, I found that even though I could barely focus for a few minutes at a time and I wasn’t really supposed to look at screens, I kept returning to the “Introduction to Cybersecurity” course, and I quickly finished it. It opened up a new, scifi-esque world of threats, risks, and vulnerabilities in a swiftly evolving cyber landscape.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Cybersecurity was a way to engage with the world in a new and exciting way!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Inspired, I went on Coursera and signed up for the Google Cybersecurity Certificate. In less than a month, I had earned my certificate and significantly increased my knowledge base.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/02.jpg&quot; alt=&quot;Dark Brain&quot; style=&quot;width: 100%; height: auto;&quot; /&gt;
&lt;em&gt;Image generated by AI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;On another trip back from Cloud Cap on Mt. Hood, I was listening to Episode 22 of “The I.T. Career Podcast” with Christophe Limpalair, and he recommended making a blog to document what you’re learning. Limpalair listed two benefits of starting a blog. One is that by teaching others, you actually learn better yourself. Second is that you can preserve a record of your expanding knowledge base for future employers.&lt;/p&gt;

&lt;p&gt;With that in mind, I asked an AI assistant, Grok, what the most secure way to build a website was and how to turn it into a learning lab. I will get more into the recipe Grok provided and my own modifications in a future blog post. It was quite a steep learning curve, but here we are!&lt;/p&gt;

&lt;p&gt;Turning to the future, I have just bought vouchers for the CompTIA Security+ and CompTIA Network+ and I am stoked prepare for those. I will be documenting my progress here, as well as any other interesting cybersecurity lessons I learn along the way.&lt;/p&gt;

&lt;p&gt;Thank you for joining me on this journey!&lt;/p&gt;
</description>
                <pubDate>Fri, 15 Aug 2025 15:31:05 -0700</pubDate>
                <link>http://localhost:4000/first-post-ever</link>
                <guid isPermaLink="true">http://localhost:4000/first-post-ever</guid>
                
                <category>study</category>
                
                <category>personal</category>
                
                
            </item>
        
    </channel>
</rss>